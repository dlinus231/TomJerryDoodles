{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Reshape\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, LeakyReLU\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from enum import Enum\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import EarlyStopping \n",
    "from PIL import Image\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Directory: /Users/miranyildirim/Desktop/DIS/Neural/final\n"
     ]
    }
   ],
   "source": [
    "# GLOBAL VARIABLES \n",
    "os.chdir('/Users/miranyildirim/Desktop/DIS/Neural/final')\n",
    "print(\"Working Directory:\", os.getcwd())\n",
    "# directories containing desired output, i.e. our y-labels, the ground truth \n",
    "outputDirectories = [\"TomJerryDoodles/archive/tom_and_jerry/tom_and_jerry/jerry\", \n",
    "                     \"TomJerryDoodles/archive/tom_and_jerry/tom_and_jerry/tom\", \n",
    "                    #  \"archive/tom_and_jerry/tom_and_jerry/tom_jerry_0\",\n",
    "                     \"TomJerryDoodles/archive/tom_and_jerry/tom_and_jerry/tom_jerry_1\"]\n",
    "\n",
    "# directories containing edge-filtered images\n",
    "inputDirectories = [\"TomJerryDoodles/archive/tom_and_jerry/tom_and_jerry_edge_detected/jerry_edge_detected\", \n",
    "                    \"TomJerryDoodles/archive/tom_and_jerry/tom_and_jerry_edge_detected/tom_edge_detected\", \n",
    "                    # \"archive/tom_and_jerry/tom_and_jerry_edge_detected/tom_jerry_0_edge_detected\",\n",
    "                    \"TomJerryDoodles/archive/tom_and_jerry/tom_and_jerry_edge_detected/tom_jerry_1_edge_detected\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER FUNCTIONS\n",
    "\"\"\" Returns file paths for all images in the input and output directories\n",
    "\n",
    "    Returns:\n",
    "        List(Tuples): each tuple contains paths to two corresponding images, the first is the edge-filtered image, the second is the unaltered image\n",
    "\"\"\"\n",
    "def getFilePaths(): \n",
    "    dataset = []\n",
    "    for inputDir, outputDir in zip(inputDirectories, outputDirectories): \n",
    "        fileNames = os.listdir(inputDir)\n",
    "        for fileName in fileNames: \n",
    "            inputImagePath = os.path.join(inputDir, fileName)\n",
    "            outputImagePath = os.path.join(outputDir, fileName)\n",
    "            dataset.append((inputImagePath, outputImagePath))\n",
    "    return dataset\n",
    "\n",
    "# takes in two paths of paired images, \n",
    "# optionally, one can specify the desired resolution of the image\n",
    "# whether to display the retrieved images, and whether to convert the images to RGB\n",
    "# will return the two images as numpy arrays, normalized by dividing by 255\n",
    "\"\"\" Returns two images as two numpy arrays, normalized by dividing by 255\n",
    "\n",
    "    Args: \n",
    "        input_file_path (str): path to an edge-filtered image\n",
    "        output_file_path (str): path corresponding to the un-modified image of the input_file_path\n",
    "        image_shape Tuple(int, int): desired width and length of the image\n",
    "        showImages (boolean): whether to display both images using matplotlib\n",
    "        isRGB (boolean): whether to convert\n",
    "\n",
    "    Returns: \n",
    "        (np.array, np.array): Two rescaled numpy arrays, representing two images\n",
    "\"\"\"\n",
    "def loadImage(input_file_path, output_file_path, \n",
    "              image_shape=(400, 200), showImages=False, isRGB = True): \n",
    "\n",
    "    input_image = Image.open(input_file_path).resize(image_shape)\n",
    "    output_image = Image.open(output_file_path).resize(image_shape)\n",
    "    beforeGrayScale = np.array(input_image)\n",
    "    # print(\"Inside loadImage():\", np.min(beforeGrayScale), np.max(beforeGrayScale))\n",
    "\n",
    "    # convert to greyscale if desired\n",
    "    if not isRGB: \n",
    "        input_image = input_image.convert(\"L\")\n",
    "        output_image = output_image.convert(\"L\")\n",
    "\n",
    "    # if desired, display the retrieved images\n",
    "    if showImages: \n",
    "        # Display images for testing\n",
    "        plt.figure(figsize=(12, 6))\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(np.array(input_image))\n",
    "        plt.title(\"Input Image\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(np.array(output_image))\n",
    "        plt.title(\"Ground Truth Image\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.show()\n",
    "    # for some reason, max pixel value from edge_detected images is 118.0\n",
    "    return np.array(input_image)/118.0, np.array(output_image)/255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = getFilePaths()\n",
    "maxesOfInput = []\n",
    "maxesOfOutput = []\n",
    "# for i in range(len(paths)): \n",
    "#     randomNum = random.randint(0, len(paths)-1)\n",
    "#     result = loadImage(paths[randomNum][0], paths[randomNum][1], image_shape=(28,28), showImages=False, isRGB=False)\n",
    "#     maxesOfInput.append(np.max(result[0]))\n",
    "#     maxesOfOutput.append(np.max(result[1]))\n",
    "    # print(np.min(result[0]), np.max(result[0]))\n",
    "    # print(np.min(result[1]), np.max(result[1]))\n",
    "# print(max(maxesOfInput))\n",
    "# print(max(maxesOfOutput))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATION OF TRAINING AND TESTING DATASETS\n",
    "\n",
    "# randomize paths so images are randomly allocated into training/testing datasets\n",
    "# random.shuffle(paths)\n",
    "validation_split = 0.2\n",
    "\n",
    "x_train, y_train = [], []\n",
    "x_test, y_test = [], []\n",
    "\n",
    "imagesProcessed = 0\n",
    "totalImagePairs = len(paths)\n",
    "\n",
    "# THIS VARIABLE AFFECTS THE DIMENSIONS OF ALL IMAGES IN THE DATASET\n",
    "# IT WILL ALSO AFFECT THE SHAPE OF THE AUTO_ENCODER\n",
    "personal_image_shape = (140, 70)\n",
    "for inputImagePath, outputImagePath in paths: \n",
    "    inputImage, imageLabel = loadImage(inputImagePath, outputImagePath, image_shape=personal_image_shape, isRGB=False)\n",
    "\n",
    "    # if validation_split = 0.2, put 80% of images into the training dataset\n",
    "    if imagesProcessed / totalImagePairs > validation_split: \n",
    "        x_train.append(inputImage)\n",
    "        y_train.append(imageLabel)\n",
    "    # else, put the images into the testing dataset\n",
    "    else: \n",
    "        x_test.append(inputImage)\n",
    "        y_test.append(imageLabel)\n",
    "        \n",
    "    imagesProcessed += 1\n",
    "\n",
    "\n",
    "# print(np.min(result[0]/255.0), np.max(result[0]/255.0))\n",
    "# print(np.min(result[1]/255.0), np.max(result[1]/255.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3159 3159\n",
      "791 791\n",
      "(3159, 70, 140)\n",
      "(3159, 70, 140)\n",
      "(791, 70, 140)\n",
      "(791, 70, 140)\n"
     ]
    }
   ],
   "source": [
    "# Confirming sizes of datsets and shapes of the datasets\n",
    "print(len(x_train), len(y_train))\n",
    "print(len(x_test), len(y_test))\n",
    "x_train, y_train, x_test, y_test = np.array(x_train), np.array(y_train), np.array(x_test), np.array(y_test)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# following guidance from the below link\n",
    "# https://www.tensorflow.org/tutorials/load_data/numpy\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "BATCH_SIZE = 64\n",
    "SHUFFLE_BUFFER_SIZE = 100\n",
    "train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_dataset = train_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_dataset = test_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(personal_image_shape[1], personal_image_shape[0], 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(personal_image_shape[1] * personal_image_shape[0], activation='sigmoid'))\n",
    "model.add(Reshape((personal_image_shape[1], personal_image_shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "50/50 [==============================] - 4s 82ms/step - loss: 0.0558 - val_loss: 0.0453\n",
      "Epoch 2/1000\n",
      "50/50 [==============================] - 4s 77ms/step - loss: 0.0351 - val_loss: 0.0355\n",
      "Epoch 3/1000\n",
      "50/50 [==============================] - 4s 81ms/step - loss: 0.0315 - val_loss: 0.0349\n",
      "Epoch 4/1000\n",
      "50/50 [==============================] - 4s 77ms/step - loss: 0.0303 - val_loss: 0.0347\n",
      "Epoch 5/1000\n",
      "50/50 [==============================] - 4s 77ms/step - loss: 0.0285 - val_loss: 0.0349\n",
      "Epoch 6/1000\n",
      "50/50 [==============================] - 4s 76ms/step - loss: 0.0262 - val_loss: 0.0351\n",
      "Epoch 7/1000\n",
      "50/50 [==============================] - 4s 76ms/step - loss: 0.0244 - val_loss: 0.0324\n",
      "Epoch 8/1000\n",
      "50/50 [==============================] - 5s 94ms/step - loss: 0.0230 - val_loss: 0.0329\n",
      "Epoch 9/1000\n",
      "50/50 [==============================] - 4s 84ms/step - loss: 0.0216 - val_loss: 0.0317\n",
      "Epoch 10/1000\n",
      "50/50 [==============================] - 5s 107ms/step - loss: 0.0210 - val_loss: 0.0311\n",
      "Epoch 11/1000\n",
      "50/50 [==============================] - 5s 107ms/step - loss: 0.0194 - val_loss: 0.0313\n",
      "Epoch 12/1000\n",
      "50/50 [==============================] - 4s 88ms/step - loss: 0.0179 - val_loss: 0.0300\n",
      "Epoch 13/1000\n",
      "50/50 [==============================] - 4s 81ms/step - loss: 0.0164 - val_loss: 0.0308\n",
      "Epoch 14/1000\n",
      "50/50 [==============================] - 4s 78ms/step - loss: 0.0154 - val_loss: 0.0308\n",
      "Epoch 15/1000\n",
      "50/50 [==============================] - 4s 80ms/step - loss: 0.0147 - val_loss: 0.0302\n",
      "Epoch 16/1000\n",
      "50/50 [==============================] - 4s 80ms/step - loss: 0.0142 - val_loss: 0.0294\n",
      "Epoch 17/1000\n",
      "50/50 [==============================] - 4s 83ms/step - loss: 0.0139 - val_loss: 0.0292\n",
      "Epoch 18/1000\n",
      "50/50 [==============================] - 5s 90ms/step - loss: 0.0137 - val_loss: 0.0291\n",
      "Epoch 19/1000\n",
      "50/50 [==============================] - 4s 82ms/step - loss: 0.0137 - val_loss: 0.0301\n",
      "Epoch 20/1000\n",
      "50/50 [==============================] - 4s 83ms/step - loss: 0.0133 - val_loss: 0.0303\n",
      "Epoch 21/1000\n",
      "50/50 [==============================] - 4s 80ms/step - loss: 0.0128 - val_loss: 0.0312\n",
      "Epoch 22/1000\n",
      "50/50 [==============================] - 4s 82ms/step - loss: 0.0130 - val_loss: 0.0303\n",
      "Epoch 23/1000\n",
      "50/50 [==============================] - 5s 108ms/step - loss: 0.0130 - val_loss: 0.0308\n",
      "Epoch 24/1000\n",
      "50/50 [==============================] - 6s 128ms/step - loss: 0.0124 - val_loss: 0.0320\n",
      "Epoch 25/1000\n",
      "50/50 [==============================] - 4s 87ms/step - loss: 0.0119 - val_loss: 0.0282\n",
      "Epoch 26/1000\n",
      "50/50 [==============================] - 5s 98ms/step - loss: 0.0115 - val_loss: 0.0277\n",
      "Epoch 27/1000\n",
      "50/50 [==============================] - 4s 88ms/step - loss: 0.0114 - val_loss: 0.0281\n",
      "Epoch 28/1000\n",
      "50/50 [==============================] - 4s 86ms/step - loss: 0.0112 - val_loss: 0.0281\n",
      "Epoch 29/1000\n",
      "50/50 [==============================] - 4s 80ms/step - loss: 0.0110 - val_loss: 0.0281\n",
      "Epoch 30/1000\n",
      "50/50 [==============================] - 4s 82ms/step - loss: 0.0108 - val_loss: 0.0292\n",
      "Epoch 31/1000\n",
      "50/50 [==============================] - 4s 81ms/step - loss: 0.0109 - val_loss: 0.0298\n",
      "Epoch 32/1000\n",
      "50/50 [==============================] - 4s 85ms/step - loss: 0.0109 - val_loss: 0.0303\n",
      "Epoch 33/1000\n",
      "50/50 [==============================] - 4s 82ms/step - loss: 0.0109 - val_loss: 0.0327\n",
      "Epoch 34/1000\n",
      "50/50 [==============================] - 4s 83ms/step - loss: 0.0108 - val_loss: 0.0315\n",
      "Epoch 35/1000\n",
      "50/50 [==============================] - 4s 83ms/step - loss: 0.0107 - val_loss: 0.0299\n",
      "Epoch 36/1000\n",
      "50/50 [==============================] - 4s 80ms/step - loss: 0.0106 - val_loss: 0.0286\n",
      "Epoch 37/1000\n",
      "50/50 [==============================] - 4s 81ms/step - loss: 0.0105 - val_loss: 0.0289\n",
      "Epoch 38/1000\n",
      "50/50 [==============================] - 5s 94ms/step - loss: 0.0105 - val_loss: 0.0306\n",
      "Epoch 39/1000\n",
      "50/50 [==============================] - 4s 84ms/step - loss: 0.0105 - val_loss: 0.0307\n",
      "Epoch 40/1000\n",
      "50/50 [==============================] - 4s 86ms/step - loss: 0.0106 - val_loss: 0.0293\n",
      "Epoch 41/1000\n",
      "50/50 [==============================] - 4s 85ms/step - loss: 0.0108 - val_loss: 0.0268\n",
      "Epoch 42/1000\n",
      "50/50 [==============================] - 4s 86ms/step - loss: 0.0105 - val_loss: 0.0273\n",
      "Epoch 43/1000\n",
      "50/50 [==============================] - 4s 87ms/step - loss: 0.0103 - val_loss: 0.0288\n",
      "Epoch 44/1000\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.0099 - val_loss: 0.0300\n",
      "Epoch 45/1000\n",
      "50/50 [==============================] - 4s 85ms/step - loss: 0.0098 - val_loss: 0.0285\n",
      "Epoch 46/1000\n",
      "50/50 [==============================] - 4s 87ms/step - loss: 0.0096 - val_loss: 0.0288\n",
      "Epoch 47/1000\n",
      "50/50 [==============================] - 5s 94ms/step - loss: 0.0095 - val_loss: 0.0291\n",
      "Epoch 48/1000\n",
      "50/50 [==============================] - 5s 88ms/step - loss: 0.0095 - val_loss: 0.0289\n",
      "Epoch 49/1000\n",
      "50/50 [==============================] - 4s 86ms/step - loss: 0.0094 - val_loss: 0.0285\n",
      "Epoch 50/1000\n",
      "50/50 [==============================] - 4s 79ms/step - loss: 0.0094 - val_loss: 0.0279\n",
      "Epoch 51/1000\n",
      "50/50 [==============================] - 4s 84ms/step - loss: 0.0095 - val_loss: 0.0288\n",
      "Epoch 52/1000\n",
      "50/50 [==============================] - 5s 97ms/step - loss: 0.0095 - val_loss: 0.0294\n",
      "Epoch 53/1000\n",
      "50/50 [==============================] - 4s 88ms/step - loss: 0.0094 - val_loss: 0.0289\n",
      "Epoch 54/1000\n",
      "50/50 [==============================] - 4s 84ms/step - loss: 0.0094 - val_loss: 0.0288\n",
      "Epoch 55/1000\n",
      "50/50 [==============================] - 4s 85ms/step - loss: 0.0092 - val_loss: 0.0287\n",
      "Epoch 56/1000\n",
      "50/50 [==============================] - 4s 85ms/step - loss: 0.0091 - val_loss: 0.0281\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', \n",
    "                               loss=losses.MeanSquaredError())\n",
    "                              #  loss=losses.MeanAbsoluteError())\n",
    "                              #  loss=losses.BinaryCrossentropy())\n",
    "\n",
    "callback = EarlyStopping(monitor=\"val_loss\", patience = 15)\n",
    "\n",
    "history = model.fit(train_dataset,\n",
    "                epochs=1000,\n",
    "                shuffle=False,\n",
    "                validation_data=(test_dataset), \n",
    "                callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 1s 11ms/step\n",
      "25/25 [==============================] - 0s 12ms/step\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_output_image_cnn = model.predict(x_train)\n",
    "test_output_image_cnn = model.predict(x_test)\n",
    "\n",
    "output_dir = '/Users/miranyildirim/Desktop/DIS/Neural/final/TomJerryDoodles/model_outputs/cnn_outputs'\n",
    "\n",
    "# Save training output images\n",
    "for i, img in enumerate(np.array(train_output_image_cnn)):\n",
    "    plt.imsave(f'{output_dir}/train_output_image_{i}.png', img)\n",
    "\n",
    "# Save testing output images\n",
    "for i, img in enumerate(np.array(test_output_image_cnn)):\n",
    "    plt.imsave(f'{output_dir}/test_output_image_{i}.png', img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
